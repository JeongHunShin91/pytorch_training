{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpIPLcO+XPYgfETwypng5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JeongHunShin91/pytorch_training/blob/main/nn_Embedding().ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "uCbQGxKeYqVU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = 'you need to know how to code'\n",
        "\n",
        "# 중복을 제거한 단어들의 집합인 단어 집합 생성.\n",
        "word_set = set(train_data.split())\n",
        "\n",
        "# 단어 집합의 각 단어에 고유한 정수 맵핑.\n",
        "vocab = {word: i+2 for i, word in enumerate(word_set)}\n",
        "vocab['<unk>'] = 0\n",
        "vocab['<pad>'] = 1\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SNK9moZXpYm",
        "outputId": "d9d49841-021c-4cf9-a51b-768880a321f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'how': 2, 'need': 3, 'you': 4, 'code': 5, 'to': 6, 'know': 7, '<unk>': 0, '<pad>': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 집합의 크기만큼의 행을 가지는 테이블 생성.\n",
        "embedding_table = torch.FloatTensor([\n",
        "                               [ 0.0,  0.0,  0.0],\n",
        "                               [ 0.0,  0.0,  0.0],\n",
        "                               [ 0.2,  0.9,  0.3],\n",
        "                               [ 0.1,  0.5,  0.7],\n",
        "                               [ 0.2,  0.1,  0.8],\n",
        "                               [ 0.4,  0.1,  0.1],\n",
        "                               [ 0.1,  0.8,  0.9],\n",
        "                               [ 0.6,  0.1,  0.1]])"
      ],
      "metadata": {
        "id": "DsB44aj1Ymyz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = 'you need to run'.split()\n",
        "idxes = []\n",
        "\n",
        "# 각 단어를 정수로 변환\n",
        "for word in sample:\n",
        "  try:\n",
        "    idxes.append(vocab[word])\n",
        "  # 단어 집합에 없는 단어일 경우 <unk>로 대체된다.\n",
        "  except KeyError:\n",
        "    idxes.append(vocab['<unk>'])\n",
        "idxes = torch.LongTensor(idxes)\n",
        "\n",
        "# 각 정수를 인덱스로 임베딩 테이블에서 값을 가져온다.\n",
        "lookup_result = embedding_table[idxes, :]\n",
        "print(lookup_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31eioIxHYm5F",
        "outputId": "739101f0-c996-4ff7-b019-a01c663a78fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2000, 0.1000, 0.8000],\n",
            "        [0.1000, 0.5000, 0.7000],\n",
            "        [0.1000, 0.8000, 0.9000],\n",
            "        [0.0000, 0.0000, 0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = 'you need to know how to code'\n",
        "\n",
        "# 중복을 제거한 단어들의 집합인 단어 집합 생성.\n",
        "word_set = set(train_data.split())\n",
        "\n",
        "# 단어 집합의 각 단어에 고유한 정수 맵핑.\n",
        "vocab = {tkn: i+2 for i, tkn in enumerate(word_set)}\n",
        "vocab['<unk>'] = 0\n",
        "vocab['<pad>'] = 1"
      ],
      "metadata": {
        "id": "EXev1p47Ym_9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "embedding_layer = nn.Embedding(num_embeddings=len(vocab), \n",
        "                               embedding_dim=3,\n",
        "                               padding_idx=1)"
      ],
      "metadata": {
        "id": "y5VKx6BFYnGN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHVNgFxNXpeu",
        "outputId": "aa1d4f63-3aee-49a6-bdda-07032b969ba6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0184,  0.4339,  1.9801],\n",
            "        [ 0.0000,  0.0000,  0.0000],\n",
            "        [ 0.5131,  0.3215,  1.3380],\n",
            "        [-1.7276, -1.3359,  0.6073],\n",
            "        [-0.9585, -0.6492,  1.2612],\n",
            "        [ 0.3982, -0.3249,  1.0292],\n",
            "        [-0.8569, -0.0748,  0.1809],\n",
            "        [-0.6454,  1.1040, -0.6049]], requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}